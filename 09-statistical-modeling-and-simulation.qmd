---
execute:
  freeze: auto  # re-render only when source changes
  warning: false
  message: false
editor: source
---

# Regression & Simulating Distributions

```{r, include = FALSE}
bytes <- file.size("09-statistical-modeling-and-simulation.qmd")
words <- bytes/10
minutes <- words/200
```

```{r setup, include = FALSE}
library(quarto)
library(fontawesome)
library(ggplot2)
fa_html_dependency()
library(knitr)
library(kableExtra)
library(tidyverse)
# htmltools::tagList(rmarkdown::html_dependency_font_awesome())
```

`r fa("book-open")` Reading: `r ceiling(minutes)` minute(s) at 200 WPM

`r fa("video")` Videos: 48 minutes

## Objectives {#ch9-objectives -}

This chapter is heavily from Dr. Theobold's course-page material.

::: check-in
## Check-ins {#ch9-checkins -}

There are two check-ins for this week:

+ [Check-in 9.1: Linear Regression](#checkin9-1)
+ [Check-in 9.2: Distributions and Simulations](#checkin9-2) 

:::

## Linear Regression

You now have the skills to import, wrangle, and visualize data. All of these tools help us prepare our data for statistical modeling. In this chapter we will be learning how to implement linear regression models in R, but first let's review simple linear regression. Linear regression models the linear relationship between two quantitative variables.

::: column-margin

::: youtube-video-container
<iframe width="100%" height="auto" src="https://www.youtube.com/embed/1IMpg1ukMpY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
:::

<br>

::: youtube-video-container
<iframe width="100%" height="auto" src="https://www.youtube.com/embed/LD3OSSVxKMU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
:::

:::

::: go-read
#### Review of Simple Linear Regression and Conditions {-}
[Recommended Reading -- *Modern Dive* : Basic Regression](https://moderndive.com/5-regression.html)

Handy function shown in the reading! `skim` from the `skimr` package.
:::

### Linear Regression in R

To demonstrate linear regression in R, we will be working with the `penguins` data set.

```{r}
library(palmerpenguins)
data(penguins)
head(penguins) |> 
  kable()
```

When conducting linear regression with tools in R, we often want to **visualize the relationship** between the two quantitative variables of interest with a scatterplot. We can then use either `geom_smooth(method = "lm")` (or equivalently `stat_smooth(method = "lm")` to add a line of best fit ("regression line") based on the ordinary least squares (OLS) equation to our scatter plot. The regression line is shown in a default blue line with the standard error uncertainty displayed in a gray transparent band (use `se = FALSE` to hide the standard error uncertainty band). These visual aesthetics can be changed just as any other plot aesthetics.

```{r}
#| message: false
#| warning: false
penguins |>
  ggplot(aes(x = bill_depth_mm, 
             y = bill_length_mm
             )
         ) +
  geom_point() +
  geom_smooth(method = "lm") + 
  labs(x = "Bill Depth (mm)",
       subtitle = "Bill Length (mm)",
       title = "Relationship between penguin bill length and depth"
       ) +
  theme(axis.title.y = element_blank())
```

::: watchout
Be careful of "overplotting" and use `geom_jitter()` instead of `geom_point()` if your data set is dense. This is strictly a data visualization tool and will not alter the original values.
:::

In simple linear regression, we can define the linear relationship with a mathematical equation given by:

$$y = a + b\cdot x$$

::: column-margin
::: note
Remember $y = m\cdot x+b$ from eighth grade?!
:::
:::

where

+ $y$ are the values of the response variable,
+ $x$ are the values of the explanatory/predictor variable,
+ $a$ is the $y$-intercept (**average** value of $y$ when $x = 0$), and
+ $b$ is the slope coefficient (for every 1 unit increase in $x$, the **average** of $y$ increases by b)

::: column-margin
::: note
Remember "rise over run"!
:::
:::

In statistics, we use slightly different notation to denote this relationship with the estimated linear regression equation:

$$\hat y = b_0 + b_1\cdot x.$$

Note that the "hat" symbol above our response variable indicates this is an "estimated" value (or our best guess).

We can **"fit" the linear regression** equation with the `lm` function in R. The `formula` argument is denoted as `y ~ x` where the left hand side (LHS) is our response variable and the right hand side (RHS) contains our explanatory/predictor variable(s). We indicate the data set with the `data` argument and therefore use the variable names (as opposed to vectors) when defining our formula. We name (`my_model)` and save our fitted model just as we would any other R object.

```{r}
my_model <- lm(bill_length_mm ~ bill_depth_mm, 
               data = penguins
               )
```

Now that we have fit our linear regression, we might be wondering how we actually *get* the information out of our model. What are the y-intercept and slope coefficient estimates? What is my residual? How good was the fit? The code options below help us obtain this information.

::: panel-tabset
##### Raw Coefficients
This is what is output when you just call the name of the linear model object you created (`my_model`). Notice, the output doesn't give you much information and it looks kind of bad.

```{r}
my_model
```

##### Model Summary
This is what is output when you use the `summary()` function on a linear model object. Notice, the output gives you a lot of information, some of which is really not that useful. And, the output is quite messy!

```{r}
summary(my_model)
```

##### Tidy Model Summary

The `tidy()` function from the {broom} package takes a linear model object and puts the "important" information into a tidy tibble output.

Ah! Just right!

```{r}
library(broom)
tidy(my_model) 
```

If you are sad that you no longer have the statistics about the model fit (e.g., R-squared, adjusted R-squared, $\sigma$), you can use the `glance()` function from the broom package to grab those!

```{r}
broom::glance(my_model)
```
:::

::: check-in
### Check-in 9.1: Linear Regression {#checkin9-1 -}

**1. True or False -- If you switch the order of `bill_length_mm` and `bill_depth_mm` in the `lm()` formula nothing happens.**

**2. What _object type_ was returned by `summary()`?**

**3. What _object type_ was returned by `tidy()`?**

**4. What is the equation for the estimated regression line for the relationship between bill length and depth (given above)?**

**5. Penguin Mopsy has a bill that is 5mm deeper than Penguin Gidget. What will be the difference between their bill lengths?**

**6. Run the following code, and explore the results:**

```{r}
my_model_2 <- lm(bill_length_mm ~ bill_depth_mm*species, 
                 data = penguins
                 )
```

**a.  Make a plot illustrating `my_model_2`. Upload a picture of your plot!** *(Hint: Think about what needs to change in the aesthetic of the plot featured previously?)*

**b.  Which model of the two models explains the most variance in `bill_length_mm`?**

**c.  Do the three species of penguin have the same bill shape (i.e., the relationship between length and depth)?**

:::

## Simulation

In statistics, we often want to simulate data (or create fake data) for a variety of purposes. For example, in your first statistics course, you may have flipped coins to "simulate" a 50-50 chance. In this section, we will learn how to simulate data from statistical distributions using R.

::: column-margin
::: youtube-video-container
<iframe width="100%" height="auto" src="https://www.youtube.com/embed/J5XQaxmznNE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
:::
:::

::: go-read
[Required Reading -- *R Programming for Data Science* : Simulation](https://bookdown.org/rdpeng/rprogdatascience/simulation.html)
:::

### Setting a Random Number Seed

Functions like `rnorm()` rely on something called pseudo-randomness. Because computers can never be *truly* random, complicated processes are implemented to make "random" number generation be so unpredictable as to behave like true randomness.

This means that projects involving simulation are harder to make **reproducible**. For example, here are two identical lines of code that give different results!

```{r}
rnorm(1, mean = 0, sd = 1)
```

```{r}
rnorm(1, mean = 0, sd = 1)
```

Fortunately, pseudo-randomness depends on a **seed**, which is an arbitrary number where the randomizing process starts. Normally, R will choose the seed for you, from a pre-generated vector:

```{r}
head(.Random.seed)
```

However, you can also choose your own seed using the `set.seed()` function. This guarantees your results will be consistent across runs (and hopefully computers):

```{r}
set.seed(1234)
rnorm(1, mean = 0, sd = 1)
```

```{r}
set.seed(1234)
rnorm(1, mean = 0, sd = 1)
```

Of course, it doesn't mean the results will be the same in every subsequent run if you forget or reset the seed in between each line of code!

```{r}
set.seed(1234)
rnorm(1, mean = 0, sd = 1)

## Calling rnorm() again without a seed "resets" the seed! 
rnorm(1, mean = 0, sd = 1)
```

It is very important to always set a seed at the **beginning** of a Quarto document that contains any random steps, so that your rendered results are consistent.

::: watchout
Note, though, that this only guarantees your rendered results will be the same *if the code has not changed*.

Changing up any part of the code will re-randomize everything that comes after it!
:::

When writing up a report which includes results from a random generation process, in order to ensure reproducibility in your document, use `` `r ` `` to include your output within your written description with [inline code](https://bookdown.org/yihui/rmarkdown-cookbook/r-code.html).

</details>

<details class="ex">

<summary>Reproducibility: inline code example</summary>

```{r}
my_rand <- rnorm(1, mean = 0, sd = 1)
my_rand
```
Using `r knitr::inline_expr('my_rand')` will display the result within my text: 

My random number is `r my_rand`.

Alternatively, you could have put the `rnorm` code directly into the inline text `r knitr::inline_expr('rnorm(1, mean = 0, sd = 1)')`, but this can get messy if you have a result that requires a larger chunk of code.

</details>

### Plotting Density Distributions

The code below creates a tibble *(read fancy data frame)* of 100 heights randomly simulated *(read drawn)* from a normal distribution with a mean of 67 and standard deviation of 3.

```{r}
set.seed(93401)
my_samples <- tibble(height = rnorm(n    = 100, 
                                    mean = 67, 
                                    sd   = 3)
                     )
my_samples |> 
  head()
```

To visualize the simulated heights, we can look at the density of the values. We plot the simulated values using `geom_histogram()` and define the local $y$ aesthetic to plot calculate and plot the density of these values. We can then overlay the normal distribution curve (theoretical equation) with our specified mean and standard deviation using `dnorm` within `stat_function()`

```{r}
my_samples |> 
  ggplot(aes(x = height)) +
  geom_histogram(aes(y = ..density..), 
                 binwidth = 1.75, 
                 fill = "grey"
                 ) +
  stat_function(fun = ~ dnorm(.x, mean = 67, sd = 3), 
                col = "cornflowerblue", 
                lwd = 2
                ) + 
  xlim(c(55, 80))
```

::: check-in
### Check-in 9.2: Distributions and Simulations {#checkin9-2 -}

**1. The `r`, `p`, `q`, and `d` functions: Try to predict what the following outputs will be _WITHOUT_ running the code in R. Drawing pictures of the relevant distributions may help. Explain what each of the functions produces in the output.**

*Yes, it is very easy to "cheat" on this question. But this is for your practice, and I recommend you give it some thought.*

a.
```{r}
#| eval: false
pnorm(-4, mean = 2, sd = 4)
```

b.
```{r}
#| eval: false
qnorm(.975, mean = 2, sd = 4)
```

c.
```{r}
#| eval: false
dnorm(1.5, mean = 2, sd = 4)
```

**2. Why does `rnorm(mean = 0, sd = 1)` give an error?**
:::

<br>

::: tryitout
## PA 9.1: Mystery Animal {-}

You will be fitting a linear regression model to a data set that contains the weights of a particular animal before and after a year of eating only roasted duck. Plotting the residuals will result in an image of a particular mystery animal.

Visit [PA 9.1 Mystery Animal](https://earobinson95.github.io/stat331-calpoly/practice-activities/PA9.1-mystery-animal.html) for instructions.
:::

<br>

::: tryitout
## PA 9.2: Instrument Con {-}

You will be simulating data from statistical distributions to determine whether Professor Hill's instruments are genuine or not.

Visit [PA 9.2 Instrument Con](https://earobinson95.github.io/stat331-calpoly/practice-activities/PA9.2-instrument-con.html) for instructions.

:::

### References {-}
